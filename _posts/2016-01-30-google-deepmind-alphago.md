---
title: "面对谷歌围棋AI，人类最后的智力骄傲即将崩塌"
date: "2016-01-30"
categories: 
  - "new-something"
tags: 
  - "ai"
  - "alphago"
  - "google"
  - "google-deepmind"
  - "人工智能"
  - "新鲜玩意"
  - "漫步云端"
---

1997年，国际象棋AI第一次打败顶尖的人类；2006年，人类最后一次打败顶尖的国际象棋AI。欧美传统里的顶级人类智力试金石，在电脑面前终于一败涂地，应了四十多年前计算机科学家的预言。

至少还有东方，人们自我安慰道。围棋AI长期以来举步维艰，顶级AI甚至不能打败稍强的业余选手。这似乎也合情合理：国际象棋中，平均每回合有35种可能，一盘棋可以有80回合；相比之下，围棋每回合有250种可能，一盘棋可以长达150回合。这一巨大的数目，足以令任何蛮力穷举者望而却步——而人类，我们相信，可以凭借某种难以复制的算法跳过蛮力，一眼看到棋盘的本质。

但是，无论人怎么想，这样的局面当然不可能永远延续下去。就在今天，国际顶尖期刊《自然》封面文章报道了谷歌研究者开发的新围棋AI。这款名为“阿尔法围棋”（AlphaGo）的人工智能，在没有任何让子的情况下以5:0完胜欧洲冠军，职业围棋二段樊麾。

\[caption id="attachment\_71" align="aligncenter" width="640"\]![AlphaGo与欧洲围棋冠军樊麾的5局较量。图片来源：参考文献[1]](images/image.png) AlphaGo与欧洲围棋冠军樊麾的5局较量。图片来源：参考文献\[1\]\[/caption\]**这是人类历史上，围棋AI第一次在公平比赛中战胜职业选手。**

#### AlphaGo的战绩如何？

此次比赛和以往不同。之前的比赛中，由于AI棋力比人类弱，人类选手都会让子，而且AI主要和业余段位的棋手比赛。而AlphaGo对战樊麾是完全公平的比赛，没有让子。职业二段樊麾出生于中国，目前是法国国家围棋队总教练，已经连续三年赢得欧洲围棋冠军的称号。

研究者也让AlphaGo和其他的围棋AI进行了较量，在总计495局中只输了一局，胜率是99.8%。它甚至尝试了让4子对阵Crazy Stone，Zen和Pachi三个先进的AI，胜率分别是77%，86%和99%。可见AlphaGo有多强大。

在接下来3月份，AlphaGo将和韩国九段棋手李世乭在首尔一战，奖金是由Google提供的100万美金。李世乭是最近10年中获得世界第一头衔最多的棋手。围棋是最后一个人类顶尖高手能战胜AI的棋类游戏。之前有人预测说，AI需要再花十几年才能战胜人类。所以这场比赛或许会见证历史，我们将拭目以待。

\[caption id="attachment\_72" align="aligncenter" width="560"\]![李世乭表示很荣幸自己将与电脑公平对弈。“无论结果如何，这都会是围棋史上极具意义的事件。”他说，“我听说谷歌Deep Mind的AI出人意料地强，而且正在变得更强。但我有自信至少这次能赢。”图片来源：tygem.com](images/image.jpeg) 李世乭表示很荣幸自己将与电脑公平对弈。“无论结果如何，这都会是围棋史上极具意义的事件。”他说，“我听说谷歌Deep Mind的AI出人意料地强，而且正在变得更强。但我有自信至少这次能赢。”图片来源：tygem.com\[/caption\]

#### AI下围棋到底有多难？

计算围棋是个极其复杂的问题，比国际象棋要困难得多。围棋最大有3^361 种局面，大致的体量是10^170，而已经观测到的宇宙中，原子的数量才10^80。国际象棋最大只有2^155种局面，称为香农数，大致是10^47。

面对任何棋类，一种直观又偷懒的思路是暴力列举所有能赢的方案，这些方案会形成一个树形地图。AI只要根据这个地图下棋就能永远胜利。然而，围棋一盘大约要下150步，每一步有250种可选的下法，所以粗略来说，要是AI用暴力列举所有情况的方式，围棋需要计算250^150种情况，大致是10^360。相对的，国际象棋每盘大约80步，每一步有35种可选下法，所以只要算35^80种情况，大概是10^124。无论如何，枚举所有情况的方法不可行，所以研究者们需要用巧妙的方法来解决问题，他们选择了模仿人类大师的下棋方式。

#### 机器学习

研究者们祭出了终极杀器——“深度学习”（Deep Learning）。深度学习是目前人工智能领域中最热门的科目，它能完成笔迹识别，面部识别，驾驶自动汽车，自然语言处理，识别声音，分析生物信息数据等非常复杂的任务。

\[caption id="attachment\_73" align="aligncenter" width="640"\]![描述AlphaGo研究成果的论文成为了1月28日的《自然》杂志的封面文章。图片来源：Nature/Google DeepMind](images/image-1.jpeg) 描述AlphaGo研究成果的论文成为了1月28日的《自然》杂志的封面文章。图片来源：Nature/Google DeepMind\[/caption\]

AlphaGo 的核心是两种不同的深度神经网络。“策略网络”（policy network）和 “值网络”（value network）。它们的任务在于合作“挑选”出那些比较有前途的棋步，抛弃明显的差棋，从而将计算量控制在计算机可以完成的范围里，本质上和人类棋手所做的一样。

其中，“值网络”负责减少搜索的深度——AI会一边推算一边判断局面，局面明显劣势的时候，就直接抛弃某些路线，不用一条道算到黑；而“策略网络”负责减少搜索的宽度——面对眼前的一盘棋，有些棋步是明显不该走的，比如不该随便送子给别人吃。利用蒙特卡洛拟合，将这些信息放入一个概率函数，AI就不用给每一步以同样的重视程度，而可以重点分析那些有戏的棋着。

\[caption id="attachment\_74" align="aligncenter" width="487"\]![AlphaGo所使用的神经网络结构示意图。图片来源：参考文献[1]](images/image-1.png) AlphaGo所使用的神经网络结构示意图。图片来源：参考文献\[1\]\[/caption\]AlphaGo利用这两个工具来分析局面，判断每种下子策略的优劣，就像人类棋手会判断当前局面以及推断未来的局面一样。这样AlphaGo在分析了比如未来20步的情况下，就能判断在哪里下子赢的概率会高。

研究者们用许多专业棋局训练AI，这种方法称为监督学习（supervised learning），然后让AI和自己对弈，这种方法称为强化学习（reinforcement learning），每次对弈都能让AI棋力精进。然后他就能战胜冠军啦！

人类在下棋时有一个劣势，在长时间比赛后，他们会犯错，但机器不会。而且人类或许一年能玩1000局，但机器一天就能玩100万局。所以AlphaGo只要经过了足够的训练，就能击败所有的人类选手。

#### Google DeepMind

Google DeepMind是这个程序的创造者，我们来看一下他们萌萌的程序员。

\[caption id="attachment\_75" align="aligncenter" width="640"\]![杰米斯·哈萨比斯（Demis Hassabis） 是Google DeepMind 的CEO。图片来源：Nature Video](images/image-2.png) 杰米斯·哈萨比斯（Demis Hassabis） 是Google DeepMind 的CEO。图片来源：Nature Video\[/caption\]

\[caption id="attachment\_76" align="aligncenter" width="640"\]![文章的第一作者大卫·西尔弗（David Silver）。图片来源：Nature Video](images/image-3.png) 文章的第一作者大卫·西尔弗（David Silver）。图片来源：Nature Video\[/caption\]

Google DeepMind 去年在《自然》杂志上发表过一篇论文\[2\]，他们用增强学习的方法训练AI玩经典的Atari游戏。其实在几年前就有人研究如何让AI玩《星际争霸》，目前人类大师还是能击败AI的。电脑游戏中大量使用人工智能技术，你有没有觉得游戏变得越来越聪明了？

#### 那么……未来呢？

人工智能研究者面对这样的成就当然欣喜。深度学习和强化学习等技术完全可以用于更广泛的领域。比如最近很火的精准治疗，我们可以训练它们判断哪些治疗方案对某个特定的人有效。

但是，围棋毕竟不仅仅是一项智力成就。就像十多年前的国际象棋一样，围棋必定也会引发超出本领域之外的讨论。等到计算机能在围棋上秒杀人类的时候，围棋是不是就变成了一种无聊的游戏？人类的智力成就是不是就贬值了？AI还将在其他层面上继续碾压人类吗？传统认为AI不可能完成的任务是否也都将被逐一打破？人类最后是会进入AI乌托邦还是被AI淘汰呢？

没人知道答案。但有一点毫无疑问：AI一定会进入我们的生活，我们不可能躲开。这一接触虽然很可能悄无声息，但意义或许不亚于我们第一次接触外星生命。  

> 谷歌的深度学习技术，你也可以学！谷歌高级科学家Vincent Vanhoucke 在Udacity 开设了深度学习课程，介绍神经网络、卷积神经网络以及长短时间记忆网络（LSTM）相关知识，戳这里去上课：http://mooc.guokr.com/career/9123/Deep-Learning/ 想要仔细阅读这篇论文？马上点击下面参考文献\[1\]的链接吧。

 

#### 参考文献：

1. [David Silver, et al. "Mastering the game of Go with deep neural networks and tree search." Nature doi:10.1038/nature16961](http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html)
2. [Mnih, Volodymyr, et al. "Human-level control through deep reinforcement learning." Nature 518.7540 (2015): 529-533.](http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html)

 

#### 文章题图：Nature/Google DeepMind

 

#### 拓展阅读

[计算机围棋的一些进展](http://www.guokr.com/post/531287/)   【作者：开明】 【编辑：Ent，Calo】   本文来源于[果壳网](http://www.guokr.com/article/441144/)（微信公众号：Guokr42），授权转载，禁止二次转载，如需转载请联系[sns@guokr.com](mailto:sns@guokr.com)。 原文链接：[果壳网（guokr.com）](http://www.guokr.com/article/441144/ "果壳网")
